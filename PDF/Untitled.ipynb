{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URI: gs://pdf168/Resume.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "import re\n",
    "from google.cloud import vision\n",
    "from google.cloud import storage #!pip install --upgrade google-cloud-storage\n",
    "from google.protobuf import json_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=\"../../key.json\"\n",
    "client=vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Define the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1 #How many page\n",
    "mime_type= 'application/pdf'#file type\n",
    "\n",
    "#Initiate a feature object\n",
    "feature = vision.types.Feature(\n",
    "    type=vision.enums.Feature.Type.DOCUMENT_TEXT_DETECTION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Define the input, output and create a json file for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input\n",
    "gcs_source_uri=\"gs://pdf168/Resume.pdf\" #Uniform resource identifier\n",
    "gcs_source=vision.types.GcsSource(uri=gcs_source_uri) \n",
    "\n",
    "#Mime_type: The type of the file. Currently only \n",
    "#\"application/pdf\", \"image/tiff\" and \"image/gif\" are supported.\n",
    "\n",
    "input_config=vision.types.InputConfig(\n",
    "    gcs_source=gcs_source, \n",
    "    mime_type=mime_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output\n",
    "file_name=\"pdf_result\"\n",
    "gcs_destination_uri=\"gs://pdf168/pdf_result\"  \n",
    "gcs_destination=vision.types.GcsDestination(uri=gcs_destination_uri)\n",
    "\n",
    "output_config=vision.types.OutputConfig(\n",
    "    gcs_destination=gcs_destination,\n",
    "    batch_size=1 #Have to do with the number of json file created\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An offline file annotation request.\n",
    "#AsyncAnnotate: asynchronous (at the same time) image detection and annotation for a list of generic files\n",
    "async_request=vision.types.AsyncAnnotateFileRequest(\n",
    "    features=[feature], #Here is type: DOCUMENT_TEXT_DETECTION\n",
    "    input_config=input_config,\n",
    "    output_config=output_config\n",
    ")\n",
    "\n",
    "operation=client.async_batch_annotate_files(requests=[async_request])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Retrieve the offline version of the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the request has completed and the output has been\n",
    "# written to GCS, we can list all the output files.\n",
    "storage_client=storage.Client()\n",
    "\n",
    "#Check if the uri is in a certain form\n",
    "match=re.match('gs://([^/]+)/(.+)', gcs_destination_uri) \n",
    "bucket_name=match.group(1) #extract the first bracket (gcs folder name)\n",
    "prefix=match.group(2) #extract the second bracket (output file name)\n",
    "bucket=storage_client.get_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files\n",
      "pdf_resultoutput-1-to-1.json\n"
     ]
    }
   ],
   "source": [
    "#List object with the given prefix \n",
    "#Note that the prefix here is the name of our output\n",
    "blob_list=list(bucket.list_blobs(prefix=prefix))\n",
    "print('Output files')\n",
    "for blob in blob_list:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Blob: pdf168, pdf_resultoutput-1-to-1.json, 1580543442820372>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the first output file from GCS. There is only 1 output in \n",
    "# this case\n",
    "\n",
    "output=blob_list[0]\n",
    "json_string = output.download_as_string()\n",
    "response=json_format.Parse(\n",
    "    json_string, vision.types.AnnotateFileResponse()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual response for the first page of the input file\n",
    "first_page_response=response.responses[0]\n",
    "annotation=first_page_response.full_text_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUY BUI\n",
      "Phone: 737-202-9999| Email: williamhuybui@gmail.com​| GitHub: williamhuybui | Website: github.io​ | LinkedIn: Huy Bui\n",
      "Data scientist and mathematician who enjoys wrangling with data and discovering new insights. Experience in producing statistical analysis, data visualization, advanced predictive models, and neural networks. With a background in teaching and studying advanced mathematics, I can communicate analytical results to both technical and non-technical audiences. I am a quick learner who has strong attention to detail and work well in a team.\n",
      "Python, data wrangling (Pandas, Numpy), data exploration (matplotlib, Tableau, PowerBI), machine learning (Scikit-learn), neural networks (PyTorch, TensorFlow, Keras), SQL, NLTK, web scraping (BeautifulSoup, Selenium), LaTex, C++, MatLab Fluent in Vietnamese (native)\n",
      "Predicting Early Childhood Learning Outcome through PBS Kids Measure Up + Reduced 11 million observations to 14 thousand by strategically grouping, aggregating, and cleaning the data + Compared multiple approaches such as blending ensembles models, multi-layered multi-classification, and regression on classification through quadratic weighted kappa metric and accuracy group distribution + Generated 800+ from 11 features and use different techniques to handle imbalanced classes + Obtained top 13% on Kaggle leaderboard by the time submitted Iowa Ames House Price Prediction Using Advanced Regression + Analyzed 79 different features of houses data to gain insight using descriptive statistics and Tableau + Handled missing data, filtered noises, experimented different encoding schemes, and removed overfitting features + Hyper-tuned and blended 6 models: Ridge, Lasso, ElasticNet, SVR, LightGBM, and XGBoost models + Reached top 7% on Kaggle leaderboard by the time submitted U.S. Accident Analysis and Severity Prediction + Analyzed the U.S accidents dataset and other external sources to answer questions with Tableau visualizations that can benefit State Farm and the company’s customers. + Produced a ML models that predict 4 types of accident severity based on 85 features with the accuracy of 66% + Won third place in the State Farm challenge at the TAMUHACK 2020\n",
      "Texas A&M University, Teaching Assistant August 2017 - May 2019 + Lectured recitation, held office hours and created test assessments for Calculus and Discrete Mathematics + Taught calculus-based computations and plotting utilities in Python and Matlab University of Houston Downtown, Math Tutor and Scholars Academy Peer Mentor August 2013 - May 2017 + Assisted college students in the upper-level math and computer science classes + Organized events to help student mentees adapt to college life and forge meaningful connections between professors and students\n",
      "Flatiron School, Houston, Texas December 2019 + Immersive Data Science Bootcamp program + Leader of 1st Place Team at Glasstire DataHack +​Participated in 3 Kaggle competitions Texas A&M University, College Station, Texas August 2019 + Master of Science in Mathematics with a focus on Algebra and Combinatorics University of Houston Downtown, Houston, Texas May 2017 + Bachelor of Science in Mathematics; Minor in Computer Science + Summa Cum Laude + President of the Mathematical Association of America student chapter\n",
      "SKILLS\n",
      "TECHNICAL PROJECTS\n",
      "EMPLOYMENT HISTORY\n",
      "EDUCATION\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we print the full text from the first page.\n",
    "# The response contains more information:\n",
    "# annotation/pages/blocks/paragraphs/words/symbols\n",
    "# including confidence scores and bounding boxes\n",
    "print(annotation.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
